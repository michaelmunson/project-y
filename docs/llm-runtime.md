# LLM Runtime
Allow an LLM to manage its context by executing subroutines in an isolated context and only returning the necessary results

## General idea
LLMs can use tools - when they call a function (by using special syntax) the result of the function is concatenated to
the completion and then fed back into the LLM as input.

Since reasoning LLMs are good at breaking down high level problems, they should be able to figure out when to delegate a
sub task to "another agent" and then simply use whatever the output that was generated by that agent was.

The idea behind this runtime is to create a general framework that allows LLMS to call themselves in a way that
avoids overly large context that would otherwise be needed for long tasks.

## Keywords & syntax

### RETURN (<value>.*)
  - returns the value from the current stack frame into the parent stack frame

### CALL <FUNCTION> (<argument>.*)

  - invokes a function with specific arguments
  - this could be a tool, e.g. QUERY-DB, or it could be a special function, like "ME" which creates a new stack frame and runs the agent with the arguments
  - some functions are asynchronous - those functions

### AWAIT <TICKET>
  - pauses the runtime until the value from that await is available
